This regulation outlines rules for the use and development of artificial intelligence (AI) systems in the EU. It limits third-party conformity assessment for high-risk AI systems, with exceptions for remote biometric identification systems. Notified bodies should be designated for third-party conformity assessment. AI systems should undergo new conformity assessments for significant modifications or changes in purpose. High-risk AI systems should bear the CE marking for conformity and free movement within the internal market. Member States can authorize non-conformity assessed AI systems for public security or protection of life and health. Providers of high-risk AI systems should register their systems in an EU database. AI systems interacting with natural persons or generating content should have specific transparency obligations. Regulatory sandboxes should be established for testing innovative AI systems. The regulation also establishes a European Artificial Intelligence Board for advisory tasks. Member States should designate national competent authorities for supervising the application and implementation of this regulation. Providers should have a post-market monitoring system in place. The regulation also encourages the development of non-high-risk AI systems in accordance with the requirements of this regulation. The regulation applies to providers and users of AI systems in the Union and those located in a third country where the output is used in the Union.